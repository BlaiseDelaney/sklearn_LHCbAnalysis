{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/04\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from root_numpy import tree2array, root2array, rec2array\n",
    "import numpy as np\n",
    "import ROOT\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas.core.common as com\n",
    "from pandas.core.index import Index\n",
    "from pandas.tools import plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert skimmed MC trees to numpy arrays\n",
    "MCdir = '/var/pcfst/r01/lhcb/delaney/Analysis/LHCbAnalysis/Bc2Dmunu/sub_jobs_MC_SB/'\n",
    "BkgMC='MCBu2DMuNu.root'\n",
    "SigMC='MCBc2DMuNu.root'\n",
    "\n",
    "bkgFile = ROOT.TFile(MCdir+BkgMC)\n",
    "sigFile = ROOT.TFile(MCdir+SigMC)\n",
    "\n",
    "bkgTree = bkgFile.Get('AnalysisTree')\n",
    "sigTree = sigFile.Get('AnalysisTree')\n",
    "\n",
    "\n",
    "#eventually load one tree and include itype selection\n",
    "Sevtmax=-1\n",
    "Bevtmax=100000\n",
    "\n",
    "\n",
    "#should rename with string manipulation\n",
    "#'B_plus_MCORRERR/B_plus_MCORR' bdt output correlated with MCORR\n",
    "branches=['TMath::Log(B_plus_PT)', \n",
    "'TMath::Log(B_plus_IPCHI2_OWNPV)', 'TMath::ACos(B_plus_DIRA_OWNPV)', 'B_plus_LTIME', 'TMath::Log(D0_PT)','TMath::Log(D0_IPCHI2_OWNPV)',\n",
    "'TMath::Log(Mu_plus_PT)', 'TMath::Log(Mu_plus_MIPCHI2PV)'] \n",
    "\n",
    "sigArray = tree2array(sigTree, branches,selection = 'B_plus_LTIME>0', start=0, stop=Sevtmax) \n",
    "sig=rec2array(sigArray)\n",
    "\n",
    "bkgArray = tree2array(bkgTree, branches,selection = 'B_plus_LTIME>0', start=0, stop=Bevtmax) \n",
    "bkg=rec2array(bkgArray)\n",
    "\n",
    "\n",
    "print '\\n--- Selected %i entries to read in from MC ---\\n'%(len(sig)+len(bkg))\n",
    "print '--- %s signal events and %s bkg events ---\\n'%(len(sig),len(bkg))\n",
    "\n",
    "\n",
    "#scikit learn requires 2D array (n_samples, n_features)\n",
    "X = np.concatenate((sig, bkg))\n",
    "y = np.concatenate((np.ones(sig.shape[0]),\n",
    "                    np.zeros(bkg.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dev,X_eval, y_dev,y_eval = train_test_split(X, y, test_size=.4, random_state=23)\n",
    "X_train,X_test, y_train,y_test = train_test_split(X_dev, y_dev, test_size=0.4, random_state=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def optimize_performance(clf, pars):\n",
    "    \n",
    "    def grid_search(clf, pars):\n",
    "        \n",
    "        grid = GridSearchCV(clf, \n",
    "                            param_grid=pars, \n",
    "                            n_jobs=-1, \n",
    "                            scoring='roc_auc',\n",
    "                            cv=3)\n",
    "        grid.fit(X_dev, y_dev)\n",
    "        return grid\n",
    "\n",
    "    grid=grid_search(clf, pars)\n",
    "    \n",
    "    print ' ##### %s #####'%clf \n",
    "  \n",
    "    print \"Best parameter set found on development set:\"\n",
    "    print\n",
    "    print grid.best_estimator_\n",
    "    print\n",
    "    print \"Grid scores on a subset of the development set:\"\n",
    "    print\n",
    "    for params, mean_score, scores in grid.grid_scores_:\n",
    "        print \"%0.4f (+/-%0.04f) for %r\"%(mean_score, scores.std(), params)\n",
    "    print\n",
    "    print \"With the model trained on the full development set:\"\n",
    "\n",
    "    y_true, y_pred = y_dev, grid.decision_function(X_dev)\n",
    "    print \"  It scores %0.4f on the full development set\"%roc_auc_score(y_true, y_pred)\n",
    "    y_true, y_pred = y_eval, grid.decision_function(X_eval)\n",
    "    print \"  It scores %0.4f on the full evaluation set\"%roc_auc_score(y_true, y_pred)\n",
    "  \n",
    "\n",
    "    #return grid.best_score_, grid.best_estimator_\n",
    "    results[grid.best_estimator_] = grid.best_score_\n",
    "    #clf = sorted(results.iteritems(), key=lambda (k,v): (v,k), reverse=True)[0][0]\n",
    "    \n",
    "    return grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3) #if max_depth=None, nodes expanded until leaves are pure\n",
    "bdt = AdaBoostClassifier(base_estimator=dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdt_param_grid ={'n_estimators': [10, 30, 50,100, 200, 500, 800, 1000],\n",
    "                 'learning_rate': [.1, .2, .5]}\n",
    "\n",
    "bdt = optimize_performance(bdt, bdt_param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fit data and evaluate performance\n",
    "bdt.fit(X_train, y_train)\n",
    "bdty_predicted = bdt.predict(X_test)\n",
    "print classification_report(y_test, bdty_predicted,\n",
    "                                    target_names=[\"background\", \"signal\"])\n",
    "print \"Area under ROC curve: %.4f\"%(roc_auc_score(y_test, bdt.decision_function(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs=[]\n",
    "\n",
    "params = ((.5,3), (.5,5), (.5, 7),\n",
    "          (.2,3), (.2,5), (.2, 7))\n",
    "\n",
    "for learn, depth in params:\n",
    "    print 'learn %f, depth %f'%(learn, depth)\n",
    "    cdt = DecisionTreeClassifier(max_depth=depth) \n",
    "    clf = AdaBoostClassifier(base_estimator=cdt, learning_rate=learn, n_estimators=1000)\n",
    "    clf.fit(X_train, y_train) #train\n",
    "    clfs.append(clf)\n",
    "\n",
    "\n",
    "def validation_curve(clfs, train, test):\n",
    "    plt.figure()\n",
    "    X_test, y_test = test\n",
    "    X_train, y_train = train\n",
    "    \n",
    "    for n,clf in enumerate(clfs):\n",
    "        print 'Added BDT with decision tree base classifier: %s\\n'%clf\n",
    "        \n",
    "        #for every estimator save train and test score\n",
    "        test_score = np.empty(len(clf.estimators_))\n",
    "        train_score = np.empty(len(clf.estimators_))\n",
    "##\n",
    "##        #compute the score at every iteration\n",
    "        for i, pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "            test_score[i] = 1- roc_auc_score(y_test, pred)\n",
    "##\n",
    "        for i, pred in enumerate(clf.staged_decision_function(X_train)):\n",
    "            train_score[i] = 1-roc_auc_score(y_train, pred)\n",
    "#         \n",
    "##\n",
    "##        #plot vertical line at best score location\n",
    "##        \n",
    "        best_iter = np.argmin(test_score)\n",
    "        print '-------- best iteration at %s for %s'%(best_iter, clf)\n",
    "        learn = clf.get_params()['learning_rate']\n",
    "        depth = clf.base_estimator.get_params()['max_depth']\n",
    "##        \n",
    "        test_line = plt.plot(\n",
    "                    test_score,\n",
    "                    label='learn=%.1f depth=%i (%.2f)'%(learn,depth, test_score[best_iter])\n",
    "                            )\n",
    "##        \n",
    "        colour = test_line[-1].get_color()\n",
    "        plt.plot(train_score, '--', color=colour)\n",
    "##        \n",
    "        plt.xlabel(\"Number of boosting iterations\")\n",
    "        plt.ylabel(\"1 - area under ROC\")\n",
    "        plt.axvline(x=best_iter, color=colour)\n",
    "##        \n",
    "    plt.legend(loc='best')\n",
    "##    plt.savefig('Plots/validation.pdf')\n",
    "##\n",
    "##\n",
    "validation_curve(clfs,\n",
    "                 (X_train,y_train),\n",
    "                 (X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_train_test(clf, X_train, y_train, X_test, y_test, bins=30):\n",
    "    decisions = []\n",
    "    for X,y in ((X_train, y_train), (X_test, y_test)):\n",
    "        d1 = clf.decision_function(X[y>0.5]).ravel()\n",
    "        d2 = clf.decision_function(X[y<0.5]).ravel()\n",
    "        decisions += [d1, d2]\n",
    "        \n",
    "    low = min(np.min(d) for d in decisions)\n",
    "    high = max(np.max(d) for d in decisions)\n",
    "    low_high = (low,high)\n",
    "    \n",
    "    plt.hist(decisions[0],\n",
    "             color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "             histtype='stepfilled', normed=True,\n",
    "             label='S (train)')\n",
    "    plt.hist(decisions[1],\n",
    "             color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "             histtype='stepfilled', normed=True,\n",
    "             label='B (train)')\n",
    "\n",
    "    hist, bins = np.histogram(decisions[2],\n",
    "                              bins=bins, range=low_high, normed=True)\n",
    "    scale = len(decisions[2]) / sum(hist)\n",
    "    err = np.sqrt(hist * scale) / scale\n",
    "    \n",
    "    width = (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.errorbar(center, hist, yerr=err, fmt='o', c='r', label='S (test)')\n",
    "    \n",
    "    hist, bins = np.histogram(decisions[3],\n",
    "                              bins=bins, range=low_high, normed=True)\n",
    "    scale = len(decisions[2]) / sum(hist)\n",
    "    err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "    plt.errorbar(center, hist, yerr=err, fmt='o', c='b', label='B (test)')\n",
    "\n",
    "    plt.xlabel(\"BDT output\")\n",
    "    plt.ylabel(\"Arbitrary units\")\n",
    "    plt.legend(loc='best')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_train_test(bdt, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
